{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SigntoText.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMdz7tDH6j4+YdXzvRvvIrD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nirupama06/Sign_to_Text/blob/main/SigntoText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJO8l1efOusO"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255,\n",
        "                            validation_split = 0.1,rotation_range=30,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    shear_range=0.2,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    fill_mode='nearest')"
      ],
      "metadata": {
        "id": "4oDvKP4tPNKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds  = datagen.flow_from_directory(\n",
        "       'Documents/asl_alphabet_train/asl_alphabet_train',\n",
        "        target_size=(100, 100),\n",
        "        batch_size=1024,\n",
        "        subset='training',\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "ysbXJMI4Pq6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds  = datagen.flow_from_directory(\n",
        "           'Documents/asl_alphabet_train/asl_alphabet_train',\n",
        "        target_size=(100, 100),\n",
        "        batch_size=1024,\n",
        "        subset='validation',\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "C2aaCDp1P4rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, lab = next(iter(train_ds ))\n",
        "img.shape, lab.shape\n",
        "class_indices = train_ds.class_indices\n",
        "class_indices\n",
        "lab"
      ],
      "metadata": {
        "id": "cIJ4iUbVP7qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dense , Dropout\n",
        "import os\n",
        "sz=128"
      ],
      "metadata": {
        "id": "uWdF53QbP4uO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Convolution2D(16, (3, 3), input_shape=(100, 100, 3), activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(64, (3, 3), activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(128, (3, 3), activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "model.add(Dense(units=1000, activation='relu'))\n",
        "model.add(Dropout(0.40))\n",
        "model.add(Dense(units=500, activation='relu'))\n",
        "model.add(Dropout(0.40))\n",
        "model.add(Dense(units=100, activation='relu'))\n",
        "model.add(Dense(units=29, activation='softmax')) # softmax for more than 2\n",
        "\n",
        "\n",
        "model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy']) # categorical_crossentropy for more than 2\n",
        "\n",
        "\n",
        "\n",
        "model.summary()\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "early_stop = EarlyStopping(monitor='val_loss',patience=5)"
      ],
      "metadata": {
        "id": "X9G2vkrpP4w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=100\n",
        "epochs=30\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=val_ds,\n",
        "                    callbacks = [early_stop])"
      ],
      "metadata": {
        "id": "aMIRsF1QP4zL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_image = tf.io.gfile.listdir(r'Documents/asl_alphabet_test/asl_alphabet_test')\n",
        "images = []\n",
        "for f in test_image:\n",
        "    img = tf.keras.preprocessing.image.load_img(r'Documents/asl_alphabet_test/asl_alphabet_test/'+ f, color_mode = \"rgb\", target_size = (100,100))\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img=img/255\n",
        "    images.append(img)\n",
        "test=np.array(images)\n",
        "pred = model.predict(test)\n",
        "pred\n",
        "model.save('Documents/model_predict.h5')"
      ],
      "metadata": {
        "id": "G3LiLHE9PrFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Ry4jDdNAPrIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bg = None\n",
        "global camera\n",
        "\n",
        "def run_avg(image, aWeight):\n",
        "    global bg\n",
        "    # initialize the background\n",
        "    if bg is None:\n",
        "        bg = image.copy().astype(\"float\")\n",
        "        return\n",
        "\n",
        "    # compute weighted average, accumulate it and update the background\n",
        "    cv2.accumulateWeighted(image, bg, aWeight)"
      ],
      "metadata": {
        "id": "FGUhxIkwQoLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment(image, threshold=25):\n",
        "    global bg\n",
        "    # find the absolute difference between background and current frame\n",
        "    diff = cv2.absdiff(bg.astype(\"uint8\"), image)\n",
        "\n",
        "    # threshold the diff image so that we get the foreground\n",
        "    thresholded = cv2.threshold(diff,\n",
        "                                threshold,\n",
        "                                255,\n",
        "                                cv2.THRESH_BINARY)[1]\n",
        "\n",
        "    # get the contours in the thresholded image\n",
        "    (cnts, _) = cv2.findContours(thresholded.copy(),\n",
        "                                 cv2.RETR_EXTERNAL,\n",
        "                                 cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # return None, if no contours detected\n",
        "    if len(cnts) == 0:\n",
        "        return\n",
        "    else:\n",
        "        # based on contour area, get the maximum contour which is the hand\n",
        "        segmented = max(cnts, key=cv2.contourArea)\n",
        "        return (thresholded, segmented)\n"
      ],
      "metadata": {
        "id": "h6aWryLbQr6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imutils\n",
        "def main():\n",
        "    # initialize weight for running average\n",
        "    aWeight = 0.5\n",
        "\n",
        "    # get the reference to the webcam\n",
        "    camera = cv2.VideoCapture(0)\n",
        "\n",
        "    # region of interest (ROI) coordinates\n",
        "    top, right, bottom, left = 10, 350, 225, 590\n",
        "\n",
        "    # initialize num of frames\n",
        "    num_frames = 0\n",
        "    image_num = 0\n",
        "    val = 0\n",
        "\n",
        "    start_recording = False\n",
        "\n",
        "    # keep looping, until interrupted\n",
        "    while(True):\n",
        "        # get the current frame\n",
        "        (grabbed, frame) = camera.read()\n",
        "        if (grabbed == True):\n",
        "\n",
        "            # resize the frame\n",
        "            frame = imutils.resize(frame, width=700)\n",
        "\n",
        "            # flip the frame so that it is not the mirror view\n",
        "            frame = cv2.flip(frame, 1)\n",
        "\n",
        "            # clone the frame\n",
        "            clone = frame.copy()\n",
        "\n",
        "            # get the height and width of the frame\n",
        "            (height, width) = frame.shape[:2]\n",
        "\n",
        "            # get the ROI\n",
        "            roi = frame[top:bottom, right:left]\n",
        "\n",
        "            # convert the roi to grayscale and blur it\n",
        "            gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "            rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
        "            #gray = cv2.GaussianBlur(gray, (7, 7), 0)\n",
        "\n",
        "            # to get the background, keep looking till a threshold is reached\n",
        "            # so that our running average model gets calibrated\n",
        "            if num_frames < 30:\n",
        "                run_avg(gray, aWeight)\n",
        "#                 print(num_frames)\n",
        "            else:\n",
        "                # segment the hand region\n",
        "                hand = segment(gray)\n",
        "\n",
        "                # check whether hand region is segmented\n",
        "                if hand is not None:\n",
        "                    # if yes, unpack the thresholded image and\n",
        "                    # segmented region\n",
        "                    (thresholded, segmented) = hand\n",
        "\n",
        "                    # draw the segmented region and display the frame\n",
        "#                     cv2.drawContours(\n",
        "#                         clone, [segmented + (right, top)], -1, (0, 0, 255))\n",
        "\n",
        "                    if start_recording and num_frames%5==0:\n",
        "                        frame_topredict = cv2.resize(frame, (32, 32)).reshape(1, 32, 32, 3)\n",
        "                        preds = model.predict(frame_topredict)\n",
        "                        val = np.argmax(preds[0])\n",
        "                        print(val)\n",
        "        \n",
        "                    cv2.putText(clone, class_names[val], (right, bottom+15), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
        "                        \n",
        "                        \n",
        "                        # Mention the directory in which you wanna store the images followed by the image name\n",
        "#                         cv2.imwrite(\"Downloads/Dataset/FistTest/fist_\" +\n",
        "#                                     str(image_num) + '.png', thresholded)\n",
        "#                         image_num += 1\n",
        "#                         print(image_num)\n",
        "#                     cv2.imshow(\"Thesholded\", thresholded)\n",
        "\n",
        "            # draw the segmented hand\n",
        "            cv2.rectangle(clone, (left, top), (right, bottom), (0, 255, 0), 2)\n",
        "\n",
        "            # increment the number of frames\n",
        "            num_frames += 1\n",
        "\n",
        "            # display the frame with segmented hand\n",
        "            cv2.imshow(\"Video Feed\", clone)\n",
        "\n",
        "            # observe the keypress by the user\n",
        "            keypress = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "            # if the user pressed \"q\", then stop looping\n",
        "            if keypress == ord(\"q\"):\n",
        "                break\n",
        "\n",
        "            if keypress == ord(\"s\"):\n",
        "                start_recording = True\n",
        "                num_frames = 0\n",
        "\n",
        "        else:\n",
        "            print(\"[Warning!] Error input, Please check your(camera Or video)\")\n",
        "            break\n",
        "            \n",
        "    camera.release()\n"
      ],
      "metadata": {
        "id": "_6T13KodQvjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "main()\n",
        "\n",
        "# free up memory\n",
        "\n",
        "#videoCaptureObject = cv2.VideoCapture(0)\n",
        "#result = True\n",
        "#while(result):\n",
        "  #  ret,frame = videoCaptureObject.read()\n",
        "  #  cv2.imwrite(\"NewPicture.jpg\",frame)\n",
        "   # result = False\n",
        "#videoCaptureObject.release()\n",
        "#cv2.destroyAllWindows()\n",
        "# camera.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import cv2\n",
        "\n",
        "videoCaptureObject = cv2.VideoCapture(0)\n",
        "result = True\n",
        "while(result):\n",
        "    ret,frame = videoCaptureObject.read()\n",
        "    cv2.imwrite(\"NewPicture.jpg\",frame)\n",
        "    result = False\n",
        "videoCaptureObject.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "get_ipython().run_line_magic('pwd', '')"
      ],
      "metadata": {
        "id": "gCWV0O3MQ1X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YlWZAf_cPI6K"
      }
    }
  ]
}